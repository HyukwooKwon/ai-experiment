import os
import sys
from pathlib import Path
from langchain_community.document_loaders import (
    DirectoryLoader, TextLoader, CSVLoader, UnstructuredExcelLoader
)
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from config import get_company_settings  # âœ… í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°

def get_openai_credentials(company_name):
    """ íŠ¹ì • ì—…ì²´ì˜ AI ëª¨ë¸ê³¼ OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸° """
    settings = get_company_settings(company_name)
    return settings["AI_MODEL"], settings["OPENAI_API_KEY"]

def loader_selector(filepath):
    """ íŒŒì¼ ìœ í˜•ë³„ ì ì ˆí•œ ë¡œë” ì„ íƒ """
    if filepath.endswith('.txt'):
        return TextLoader(filepath, encoding='utf-8')
    elif filepath.endswith('.csv'):
        return CSVLoader(filepath, encoding='utf-8')
    elif filepath.endswith('.xlsx') or filepath.endswith('.xls'):
        return UnstructuredExcelLoader(filepath)
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {filepath}")

def create_or_update_faiss(company_name):
    """ íŠ¹ì • ì—…ì²´ì˜ ë²¡í„° DBë¥¼ ìƒì„± ë˜ëŠ” ì—…ë°ì´íŠ¸ """
    ai_model, openai_api_key = get_openai_credentials(company_name)

    # âœ… ì ˆëŒ€ ê²½ë¡œ ì„¤ì •
    base_dir = Path(__file__).resolve().parent
    company_db_path = base_dir / "database" / company_name
    faiss_db_path = base_dir / "faiss_indexes" / f"{company_name}_index"

    print(f"\nğŸ” ë²¡í„°DB ìƒì„± ì‹œì‘ - {company_name}")
    print(f"ğŸ“‚ ë°ì´í„° ê²½ë¡œ í™•ì¸: {company_db_path.resolve()}")
    
    if not company_db_path.exists():
        print(f"âŒ '{company_db_path}' í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ë²¡í„°DBë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    try:
        print(f"ğŸ“‚ {company_name}ì˜ ë¬¸ì„œë¥¼ ë¡œë”© ì¤‘...")
        files = list(company_db_path.glob("*.*"))
        print(f"ğŸ“Œ íŒŒì¼ ëª©ë¡: {files if files else 'ì—†ìŒ'}")

        if not files:
            print(f"âš ï¸ {company_name}ì˜ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ë²¡í„°DBë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return

        print(f"ğŸš€ DirectoryLoader ì‹¤í–‰ ì¤‘...")
        loader = DirectoryLoader(str(company_db_path), glob="*.*", loader_cls=loader_selector)
        documents = loader.load()
        print(f"âœ… íŒŒì¼ ë¡œë“œ ì™„ë£Œ, ë¬¸ì„œ ê°œìˆ˜: {len(documents)}")

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
        texts = text_splitter.split_documents(documents)

        print(f"ğŸ”„ ë¬¸ì„œ ì„ë² ë”© ì§„í–‰ ì¤‘...")
        vectorstore = FAISS.from_documents(texts, OpenAIEmbeddings(api_key=openai_api_key))
        vectorstore.save_local(str(faiss_db_path))

        print(f"âœ… {company_name}ì˜ ë²¡í„°DB ìƒì„± ì™„ë£Œ! ì €ì¥ ìœ„ì¹˜: {faiss_db_path}\n")

    except Exception as e:
        print(f"âŒ ë²¡í„°DB ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("âŒ ì‚¬ìš©ë²•: python create_vector_db.py <company_name>")
        sys.exit(1)

    company_name = sys.argv[1]
    print(f"âœ… create_vector_db.py ì‹¤í–‰ë¨. ì…ë ¥ëœ ì—…ì²´ëª…: {company_name}")

    create_or_update_faiss(company_name)
